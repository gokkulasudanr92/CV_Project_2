learning rate: 0.0004096836369579445, reg: 0.0004986687191569775 ---- val_acc: 0.9445, val_loss: 0.149078
learning rate: 1.9794980100741272e-07, reg: 0.23618438740973968 ---- val_acc: 0.503, val_loss: 0.727517
learning rate: 0.011320750350728031, reg: 0.024816608411291352 ---- val_acc: 0.976, val_loss: 0.0866814
learning rate: 0.023607695413054092, reg: 0.09132476485613215 ---- val_acc: 0.962, val_loss: 0.127618
learning rate: 0.30928363224529776, reg: 5.5257450610342174e-05 ---- val_acc: 0.5, val_loss: 1.50538
learning rate: 1.4894460255847152e-05, reg: 4.134512751871204e-05 ---- val_acc: 0.893, val_loss: 0.46271
learning rate: 1.6758654310999846e-05, reg: 0.19237863884041972 ---- val_acc: 0.8985, val_loss: 0.446908
learning rate: 0.08706657670333098, reg: 0.0147267827323392 ---- val_acc: 0.8815, val_loss: 0.45316
learning rate: 2.2600092457632944e-06, reg: 0.0002718921656771774 ---- val_acc: 0.687, val_loss: 0.641662
learning rate: 1.7127943312421547e-06, reg: 0.0017263436588899005 ---- val_acc: 0.714, val_loss: 0.647949
learning rate: 5.51604048080609e-07, reg: 0.4077214052096444 ---- val_acc: 0.5065, val_loss: 0.696953
learning rate: 6.332783989147562e-07, reg: 0.001237047457342641 ---- val_acc: 0.505, val_loss: 0.695182
learning rate: 1.1387741428107064e-07, reg: 0.018155305059968253 ---- val_acc: 0.5005, val_loss: 0.735991
learning rate: 8.682712301884688e-07, reg: 0.12205403600492998 ---- val_acc: 0.526, val_loss: 0.679605
learning rate: 1.1413133130436207e-05, reg: 0.0001618816863516175 ---- val_acc: 0.681, val_loss: 0.545832
learning rate: 4.5264518073859676e-05, reg: 0.015565275269572996 ---- val_acc: 0.903, val_loss: 0.330163
learning rate: 2.479480718075127e-07, reg: 5.5885867545616215e-05 ---- val_acc: 0.501, val_loss: 0.722022
learning rate: 5.447697935081425e-06, reg: 1.1041898418900005e-05 ---- val_acc: 0.717, val_loss: 0.590296
learning rate: 4.137730751011076e-06, reg: 0.257229494094834 ---- val_acc: 0.8245, val_loss: 0.596469
learning rate: 2.2975132368336811e-07, reg: 0.00014567733337432783 ---- val_acc: 0.5025, val_loss: 0.724283
learning rate: 4.2943809287905504e-06, reg: 0.0012629015223157424 ---- val_acc: 0.789, val_loss: 0.598009
learning rate: 3.0785819433087544e-06, reg: 0.00016919783944708804 ---- val_acc: 0.75, val_loss: 0.622777
learning rate: 7.041628451307914e-06, reg: 0.03766658666478994 ---- val_acc: 0.844, val_loss: 0.548977
learning rate: 2.677840118580084e-05, reg: 0.0006641481051883974 ---- val_acc: 0.8975, val_loss: 0.389164
learning rate: 3.177529946902378e-07, reg: 6.718828523949005e-05 ---- val_acc: 0.4975, val_loss: 0.715695
learning rate: 0.0005915560894847146, reg: 0.023458558480365366 ---- val_acc: 0.9415, val_loss: 0.153083
learning rate: 7.239164305706837e-06, reg: 0.017076672733504807 ---- val_acc: 0.817, val_loss: 0.552482
learning rate: 3.560408524814915e-07, reg: 0.008229682205994064 ---- val_acc: 0.5005, val_loss: 0.713531
learning rate: 0.0005203253190714865, reg: 0.0032021327931495863 ---- val_acc: 0.952, val_loss: 0.129836
learning rate: 7.175500154328019e-05, reg: 4.7991079797235106e-05 ---- val_acc: 0.8135, val_loss: 0.409812
learning rate: 1.143372243386245e-05, reg: 0.00019895411429194295 ---- val_acc: 0.8925, val_loss: 0.49014
learning rate: 0.0001767239877642238, reg: 0.0006746901364549954 ---- val_acc: 0.7485, val_loss: 0.495145
learning rate: 8.407813949862655e-07, reg: 1.72973701996701e-05 ---- val_acc: 0.513, val_loss: 0.683403
learning rate: 4.588276562766871e-05, reg: 4.4069819490980034e-05 ---- val_acc: 0.793, val_loss: 0.418737
learning rate: 7.19538005089332e-05, reg: 0.10514157733264533 ---- val_acc: 0.9265, val_loss: 0.263521
learning rate: 1.0214473446148911e-07, reg: 0.048136091774167486 ---- val_acc: 0.5005, val_loss: 0.737441
learning rate: 6.186254477970806e-07, reg: 0.0011180467974668757 ---- val_acc: 0.5065, val_loss: 0.693411
learning rate: 6.236933286117229e-05, reg: 3.564577010053435e-05 ---- val_acc: 0.937, val_loss: 0.26672
learning rate: 1.0715763591210329e-05, reg: 0.283988899288731 ---- val_acc: 0.5515, val_loss: 0.567082
learning rate: 8.947733103298358e-07, reg: 0.030517050927420804 ---- val_acc: 0.5365, val_loss: 0.677933
learning rate: 1.151684101070798e-05, reg: 0.00016478304881284206 ---- val_acc: 0.7325, val_loss: 0.534505
learning rate: 2.2966554710738505e-07, reg: 0.00013779154150429245 ---- val_acc: 0.5015, val_loss: 0.723842
learning rate: 0.00029242742203796973, reg: 0.006338685615777611 ---- val_acc: 0.749, val_loss: 0.580778
learning rate: 1.0596552413303536e-06, reg: 0.00024008390354465333 ---- val_acc: 0.5285, val_loss: 0.675711
learning rate: 1.064823092220111e-06, reg: 1.4917054901999474e-05 ---- val_acc: 0.5645, val_loss: 0.672324
learning rate: 1.635543275924837e-06, reg: 0.005048629178613399 ---- val_acc: 0.7155, val_loss: 0.651055
learning rate: 3.305223049124134e-07, reg: 0.015477085117630397 ---- val_acc: 0.4975, val_loss: 0.715369
learning rate: 0.00012674594029804523, reg: 0.03689498614993397 ---- val_acc: 0.618, val_loss: 0.717903
learning rate: 0.0007323108994150954, reg: 2.196325134439268e-05 ---- val_acc: 0.8135, val_loss: 0.431192
learning rate: 0.0004963381974999403, reg: 0.0001725647358344432 ---- val_acc: 0.741, val_loss: 0.672961
learning rate: 2.990245542781263e-07, reg: 0.005367413526107963 ---- val_acc: 0.497, val_loss: 0.716995
learning rate: 3.4938648140055796e-06, reg: 0.01147884348103828 ---- val_acc: 0.7715, val_loss: 0.613445
learning rate: 6.968425681682958e-05, reg: 0.43353328570169536 ---- val_acc: 0.514, val_loss: 0.783414
learning rate: 3.368766031652726e-05, reg: 0.02697011968443188 ---- val_acc: 0.804, val_loss: 0.426446
learning rate: 1.080974591456984e-06, reg: 0.0029191208984907253 ---- val_acc: 0.572, val_loss: 0.67164
learning rate: 2.354485062039051e-05, reg: 4.761927108964291e-05 ---- val_acc: 0.9025, val_loss: 0.400098
learning rate: 8.782917909041001e-07, reg: 1.4022152635783113e-05 ---- val_acc: 0.516, val_loss: 0.681649
learning rate: 0.000605025479950067, reg: 0.02027008370690748 ---- val_acc: 0.835, val_loss: 0.410049
learning rate: 2.886804870342869e-07, reg: 0.0017115418407089664 ---- val_acc: 0.5, val_loss: 0.719119
learning rate: 1.8795213623438274e-05, reg: 0.390628845978442 ---- val_acc: 0.8275, val_loss: 0.46482
learning rate: 2.722097680486251e-06, reg: 0.0008263479266827647 ---- val_acc: 0.717, val_loss: 0.625578
learning rate: 0.00019944300032011613, reg: 5.547121368207098e-05 ---- val_acc: 0.7845, val_loss: 0.464653
learning rate: 0.00019744843263287868, reg: 0.0156342197778219 ---- val_acc: 0.598, val_loss: 0.855822
learning rate: 1.2667045331791728e-06, reg: 0.01179838795459706 ---- val_acc: 0.611, val_loss: 0.665712
learning rate: 1.1146219001883896e-06, reg: 0.026857102987025032 ---- val_acc: 0.605, val_loss: 0.669271
learning rate: 0.0009459682010225995, reg: 4.927479295042685e-05 ---- val_acc: 0.7165, val_loss: 0.822934
learning rate: 2.0047053721523546e-06, reg: 0.027292451249201096 ---- val_acc: 0.725, val_loss: 0.64381
learning rate: 1.912510079820199e-05, reg: 0.0008965118341223315 ---- val_acc: 0.822, val_loss: 0.462469
learning rate: 3.1715753560546384e-05, reg: 8.070691108134396e-05 ---- val_acc: 0.611, val_loss: 0.564553
learning rate: 1.7786334112765128e-06, reg: 0.0002072873314710654 ---- val_acc: 0.675, val_loss: 0.651383
learning rate: 1.3724600833666726e-07, reg: 0.004614442291862369 ---- val_acc: 0.502, val_loss: 0.733387
learning rate: 5.886493655553758e-05, reg: 0.005588145882502918 ---- val_acc: 0.842, val_loss: 0.381397
learning rate: 5.096868446644331e-05, reg: 0.0021357763881245406 ---- val_acc: 0.565, val_loss: 0.59087
learning rate: 5.9248650341615375e-06, reg: 0.0012816886207678187 ---- val_acc: 0.71, val_loss: 0.585158
learning rate: 3.0254803726930958e-06, reg: 0.0015446472606300576 ---- val_acc: 0.759, val_loss: 0.622221
learning rate: 0.00015644995142911216, reg: 0.9435206583133269 ---- val_acc: 0.6355, val_loss: 0.574436
learning rate: 2.0337615207704668e-06, reg: 0.0014443923106292117 ---- val_acc: 0.68, val_loss: 0.646258
learning rate: 9.125630976701648e-05, reg: 0.0027654206786542315 ---- val_acc: 0.646, val_loss: 0.622002
learning rate: 8.033062366491157e-05, reg: 0.034027712522623356 ---- val_acc: 0.825, val_loss: 0.371878
learning rate: 2.537743887086616e-07, reg: 0.8680470527203111 ---- val_acc: 0.501, val_loss: 0.721676
learning rate: 2.3422247095158667e-06, reg: 0.07078180379988931 ---- val_acc: 0.7545, val_loss: 0.63507
learning rate: 6.992694632322322e-06, reg: 0.005533075772388188 ---- val_acc: 0.6355, val_loss: 0.58133
learning rate: 1.2273940512987275e-05, reg: 0.0016833323449692529 ---- val_acc: 0.8925, val_loss: 0.481488
learning rate: 7.950050723159484e-05, reg: 0.49052417320405906 ---- val_acc: 0.917, val_loss: 0.271328
learning rate: 1.1643046033411888e-06, reg: 0.06050871309328441 ---- val_acc: 0.5375, val_loss: 0.671627
learning rate: 0.00035809925637300417, reg: 0.07277248807970148 ---- val_acc: 0.643, val_loss: 0.888966
learning rate: 0.0001040247529561988, reg: 0.16702804363384144 ---- val_acc: 0.8705, val_loss: 0.307578
learning rate: 1.8832016871148114e-07, reg: 0.14592755992918843 ---- val_acc: 0.5035, val_loss: 0.728018
learning rate: 7.9309744203831e-05, reg: 0.21625091119951215 ---- val_acc: 0.9155, val_loss: 0.275461
learning rate: 2.064686354510014e-06, reg: 0.8638206560027194 ---- val_acc: 0.736, val_loss: 0.642076
learning rate: 1.8415945900833464e-07, reg: 0.0065214325188176344 ---- val_acc: 0.5035, val_loss: 0.72837
learning rate: 1.8104626455239528e-06, reg: 0.18113508329456596 ---- val_acc: 0.718, val_loss: 0.648219
learning rate: 4.647835923127106e-07, reg: 0.007305981292060909 ---- val_acc: 0.504, val_loss: 0.703186
learning rate: 9.876560817764322e-07, reg: 0.3287935987379776 ---- val_acc: 0.535, val_loss: 0.675788
learning rate: 1.9125166900433285e-07, reg: 0.18753658138164014 ---- val_acc: 0.503, val_loss: 0.728143
learning rate: 3.2805444064079286e-05, reg: 0.0021887779334577697 ---- val_acc: 0.523, val_loss: 0.599573
learning rate: 0.0008465283753791358, reg: 0.7523485511720975 ---- val_acc: 0.7865, val_loss: 0.578522
learning rate: 4.098540393721953e-06, reg: 0.07699060686024474 ---- val_acc: 0.774, val_loss: 0.598565
learning rate: 3.4464991390712946e-05, reg: 0.060024769905110756 ---- val_acc: 0.596, val_loss: 0.583937
learning rate: 0.0006574252177234674, reg: 0.001570354344536836 ---- val_acc: 0.9435, val_loss: 0.1531
learning rate: 2.7503953864371782e-06, reg: 0.3640983902750778 ---- val_acc: 0.7275, val_loss: 0.624504
learning rate: 1.9025523685305226e-06, reg: 0.0028163784458464904 ---- val_acc: 0.7325, val_loss: 0.64499
learning rate: 0.00012292281832528644, reg: 0.5500921144709017 ---- val_acc: 0.7895, val_loss: 0.436162
learning rate: 9.002648158133754e-07, reg: 0.47762760234015134 ---- val_acc: 0.538, val_loss: 0.67766
learning rate: 0.00010472490097119001, reg: 0.19493667027094505 ---- val_acc: 0.9125, val_loss: 0.265676
learning rate: 3.469733885679581e-07, reg: 0.29063314921061334 ---- val_acc: 0.4995, val_loss: 0.71361
learning rate: 3.5236739582735836e-06, reg: 0.04424259578352227 ---- val_acc: 0.7535, val_loss: 0.609349
learning rate: 0.00010757845023127429, reg: 0.013150935575718588 ---- val_acc: 0.5705, val_loss: 0.616114
learning rate: 0.00010768918170408093, reg: 0.010015788694119274 ---- val_acc: 0.5165, val_loss: 0.872028
learning rate: 5.466384565075247e-07, reg: 0.07683371891655218 ---- val_acc: 0.506, val_loss: 0.700141
learning rate: 9.791391235795285e-07, reg: 0.04774575390970753 ---- val_acc: 0.5935, val_loss: 0.672934
learning rate: 6.609988490830735e-07, reg: 0.002498547623863282 ---- val_acc: 0.506, val_loss: 0.693541
learning rate: 2.932056894126723e-06, reg: 0.007125608712765167 ---- val_acc: 0.7245, val_loss: 0.62121
learning rate: 2.075656055716301e-07, reg: 0.0024387095364921917 ---- val_acc: 0.5045, val_loss: 0.726111
learning rate: 1.4553867939738934e-07, reg: 0.06160974627530909 ---- val_acc: 0.502, val_loss: 0.732535
learning rate: 8.212062598304157e-06, reg: 0.3421623872712158 ---- val_acc: 0.7895, val_loss: 0.544139
learning rate: 2.4337411434157936e-07, reg: 0.08458705730437903 ---- val_acc: 0.501, val_loss: 0.722862
learning rate: 0.00033536874856729333, reg: 0.22168906455184265 ---- val_acc: 0.685, val_loss: 0.764199
learning rate: 0.0007229946853013101, reg: 0.00665248736829106 ---- val_acc: 0.736, val_loss: 0.732995
learning rate: 0.0002315366826565108, reg: 0.097267355682052 ---- val_acc: 0.953, val_loss: 0.152448
learning rate: 1.7914905680633947e-06, reg: 0.05616202766212616 ---- val_acc: 0.724, val_loss: 0.648265
learning rate: 1.6891677535151995e-07, reg: 0.002949562680432607 ---- val_acc: 0.502, val_loss: 0.730071
learning rate: 3.023449757509641e-07, reg: 0.10554827268934931 ---- val_acc: 0.5, val_loss: 0.717578
learning rate: 0.00021455262311497356, reg: 0.2507991448989842 ---- val_acc: 0.9515, val_loss: 0.157857
learning rate: 6.061629370839075e-05, reg: 0.0908309180147934 ---- val_acc: 0.5545, val_loss: 0.603265
learning rate: 3.4690515432595286e-07, reg: 0.11678622546696632 ---- val_acc: 0.499, val_loss: 0.714352
learning rate: 3.805235644883397e-07, reg: 0.005535254923073558 ---- val_acc: 0.499, val_loss: 0.711095
learning rate: 3.5017188245666375e-06, reg: 0.418706472198308 ---- val_acc: 0.733, val_loss: 0.617175
learning rate: 0.00010064399406714561, reg: 0.007752533717298941 ---- val_acc: 0.899, val_loss: 0.274513
learning rate: 5.253709176301296e-05, reg: 0.028480952985031928 ---- val_acc: 0.519, val_loss: 0.677046
learning rate: 2.4943887205609183e-06, reg: 0.3201486395603604 ---- val_acc: 0.731, val_loss: 0.629495
learning rate: 2.1046376790796085e-07, reg: 0.19677304678967558 ---- val_acc: 0.5045, val_loss: 0.726009
learning rate: 1.1240789048676536e-06, reg: 0.33577695439530786 ---- val_acc: 0.6, val_loss: 0.669559
learning rate: 0.0003879280193335548, reg: 0.3131559902684159 ---- val_acc: 0.9025, val_loss: 0.249709
learning rate: 0.00010884259233086516, reg: 0.01548670496477067 ---- val_acc: 0.931, val_loss: 0.226085
learning rate: 4.4459085915694227e-07, reg: 0.0010545829026815654 ---- val_acc: 0.5015, val_loss: 0.706986
learning rate: 0.0001814085727194607, reg: 0.013111449660608872 ---- val_acc: 0.848, val_loss: 0.331122
learning rate: 1.4757383595839532e-06, reg: 0.29088387203412236 ---- val_acc: 0.653, val_loss: 0.658805
learning rate: 0.00017767986011363784, reg: 0.002341398312497102 ---- val_acc: 0.705, val_loss: 0.52623
learning rate: 5.720565720009161e-07, reg: 0.1813180864178934 ---- val_acc: 0.506, val_loss: 0.695648
learning rate: 6.595090267260411e-05, reg: 0.03055462869034364 ---- val_acc: 0.509, val_loss: 0.810545
learning rate: 2.4549797268133516e-05, reg: 0.0020214753560754617 ---- val_acc: 0.8475, val_loss: 0.428665
learning rate: 0.00031903221293460465, reg: 0.12973712712737148 ---- val_acc: 0.5495, val_loss: 0.861394
learning rate: 8.042412563974778e-07, reg: 0.004999328193961201 ---- val_acc: 0.5145, val_loss: 0.685218
learning rate: 0.00041904621746207375, reg: 0.011443158046603836 ---- val_acc: 0.747, val_loss: 0.51261
learning rate: 3.079224573720471e-05, reg: 0.010066197545171462 ---- val_acc: 0.9255, val_loss: 0.356203
learning rate: 2.958586618327641e-07, reg: 0.004542856456810371 ---- val_acc: 0.4985, val_loss: 0.71767
learning rate: 3.013807012158348e-06, reg: 0.011585939082414976 ---- val_acc: 0.7275, val_loss: 0.619466
learning rate: 4.4661535985996604e-07, reg: 0.8487484213782047 ---- val_acc: 0.502, val_loss: 0.705723
learning rate: 3.3853972869637186e-07, reg: 0.004302047256584653 ---- val_acc: 0.4985, val_loss: 0.714786
learning rate: 0.00037824767571320513, reg: 0.012521077780920173 ---- val_acc: 0.943, val_loss: 0.152716
learning rate: 1.3694000451126815e-06, reg: 0.020223950780345397 ---- val_acc: 0.6455, val_loss: 0.661534
learning rate: 4.307763025490084e-06, reg: 0.02709410440689508 ---- val_acc: 0.796, val_loss: 0.597355
learning rate: 0.00017200909847565115, reg: 0.0020066190647202997 ---- val_acc: 0.6425, val_loss: 0.5775
learning rate: 0.0003696246918292852, reg: 0.08124071020240808 ---- val_acc: 0.9365, val_loss: 0.173001
learning rate: 0.00015168872745099994, reg: 0.4153076131034332 ---- val_acc: 0.5255, val_loss: 0.841588
learning rate: 0.00021055752183122206, reg: 0.006178693843232707 ---- val_acc: 0.5465, val_loss: 0.771694
learning rate: 3.254481529582504e-05, reg: 0.01254366747194198 ---- val_acc: 0.8015, val_loss: 0.429508
learning rate: 1.3120652880781915e-06, reg: 0.270837768461115 ---- val_acc: 0.643, val_loss: 0.662842
learning rate: 4.8075107525559464e-05, reg: 0.025715908912593982 ---- val_acc: 0.731, val_loss: 0.474421
learning rate: 3.5600231704906178e-06, reg: 0.08753177254830338 ---- val_acc: 0.7175, val_loss: 0.610821
learning rate: 2.713222616673151e-06, reg: 0.018304919875871184 ---- val_acc: 0.686, val_loss: 0.633664
learning rate: 1.5483445335946156e-07, reg: 0.19799981916405499 ---- val_acc: 0.502, val_loss: 0.731629
learning rate: 0.00033987355225534234, reg: 0.001537749605634705 ---- val_acc: 0.656, val_loss: 0.844298
learning rate: 2.8920471099807414e-06, reg: 0.0013803370331070613 ---- val_acc: 0.713, val_loss: 0.628758
learning rate: 3.7433269541881404e-06, reg: 0.08421797257972687 ---- val_acc: 0.8115, val_loss: 0.605023
learning rate: 1.3195956305340279e-06, reg: 0.010822512085313268 ---- val_acc: 0.6715, val_loss: 0.661275
learning rate: 1.304375630012692e-07, reg: 0.07781479922252912 ---- val_acc: 0.5015, val_loss: 0.734294
learning rate: 0.00027823187853267905, reg: 0.0026778457167840643 ---- val_acc: 0.897, val_loss: 0.253921
learning rate: 1.6395636871524664e-07, reg: 0.07569502196170692 ---- val_acc: 0.5025, val_loss: 0.730733
learning rate: 2.813725906319395e-07, reg: 0.001 ---- val_acc: 0.4995, val_loss: 0.719284
